{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> &uarr;   Ensure Kernel is set to  &uarr;  </div><br><div style=\"text-align: right\"> \n",
    "conda_python3  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Estimator Bring your own Script\n",
    "\n",
    "In this notebook we will go through and run a PyTorch model to classify the junctions as priority, signal and roundabout as seen in data prep.\n",
    "\n",
    "The outline of this notebook is \n",
    "\n",
    "1. to prepare a training script (provided).\n",
    "\n",
    "2. use the AWS provided PyTorch container and provide our script to it.\n",
    "\n",
    "3. Run training.\n",
    "\n",
    "4. deploy model to end point.\n",
    "\n",
    "5. Test using an image in couple of possible ways "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrade Sagemaker so we can access the latest containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.91.1)\n",
      "Requirement already satisfied: boto3>=1.20.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.21.42)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (3.7.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (3.15.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: attrs==20.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.20.21->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.42 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.20.21->sagemaker) (1.24.42)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.25.0,>=1.24.42->boto3>=1.20.21->sagemaker) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the libraries and set up the initial variables we will be using in this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "ON_SAGEMAKER_NOTEBOOK = True\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "if ON_SAGEMAKER_NOTEBOOK:\n",
    "    role = sagemaker.get_execution_role()\n",
    "else:\n",
    "    role = \"[YOUR ROLE]\"\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"mherrfurth-bucket\"\n",
    "# key = \"data-folder\"   (in case you structure your data as your-bucket/data-folder) \n",
    "training_data_uri=\"s3://{}\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Estimator\n",
    "\n",
    "Use AWS provided open source containers, these containers can be extended by starting with the image provided by AWS and the add additional installs in dockerfile\n",
    "\n",
    "or you can use requirements.txt in source_dir to install additional libraries.\n",
    "\n",
    "Below code is for PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point='ptModelCode.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.8',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.12xlarge',\n",
    "                    py_version='py3',\n",
    "                    # available hyperparameters: emsize, nhid, nlayers, lr, clip, epochs, batch_size,\n",
    "                    #                            bptt, dropout, tied, seed, log_interval\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the estimators fit method with the URI location of the training data to start the training <br>\n",
    "**Note:** This cell takes approximately **20 mins** to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:28:35 Starting - Starting the training job...\n",
      "2022-05-23 17:29:03 Starting - Preparing the instances for trainingProfilerReport-1653326915: InProgress\n",
      ".........\n",
      "2022-05-23 17:30:31 Downloading - Downloading input data......\n",
      "2022-05-23 17:31:34 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:38,545 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:38,547 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:38,555 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:38,563 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:39,333 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:39,345 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:39,355 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-23 17:31:39,364 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-05-23-17-28-34-228\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-779416346969/pytorch-training-2022-05-23-17-28-34-228/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"ptModelCode\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"ptModelCode.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=ptModelCode.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=ptModelCode\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-779416346969/pytorch-training-2022-05-23-17-28-34-228/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-05-23-17-28-34-228\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-779416346969/pytorch-training-2022-05-23-17-28-34-228/source/sourcedir.tar.gz\",\"module_name\":\"ptModelCode\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"ptModelCode.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 ptModelCode.py\u001b[0m\n",
      "\u001b[34mstarting in main\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.169 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.755 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.755 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.756 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.756 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.756 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.2.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.2.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.982 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.2.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.2.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.3.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.3.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.983 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.2.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.2.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.3.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.3.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.4.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.4.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.5.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.5.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.984 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.2.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.2.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:fc.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:591] name:fc.bias count_params:3\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:593] Total Trainable Params: 21286211\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.985 algo-1:26 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-05-23 17:31:43.991 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34mTrain loss 0.9507813453674316 accuracy 0.5633484162895928\u001b[0m\n",
      "\u001b[34mVal loss 0.8338487148284912 accuracy 0.625\u001b[0m\n",
      "\u001b[34m/opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34mEpoch 2/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.8015930750463383 accuracy 0.665158371040724\u001b[0m\n",
      "\u001b[34mVal loss 0.5524599552154541 accuracy 0.75\u001b[0m\n",
      "\u001b[34m/opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34mEpoch 3/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.7432596638619181 accuracy 0.6870286576168929\u001b[0m\n",
      "\u001b[34mVal loss 1.4565967321395874 accuracy 0.25\u001b[0m\n",
      "\u001b[34mEpoch 4/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.6350278877709286 accuracy 0.7413273001508296\u001b[0m\n",
      "\u001b[34mVal loss 0.4864024221897125 accuracy 0.75\u001b[0m\n",
      "\u001b[34mEpoch 5/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.6330122046890747 accuracy 0.7481146304675717\u001b[0m\n",
      "\u001b[34mVal loss 0.8672022223472595 accuracy 0.625\u001b[0m\n",
      "\u001b[34mEpoch 6/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.5826880924224135 accuracy 0.751131221719457\u001b[0m\n",
      "\u001b[34mVal loss 1.149198055267334 accuracy 0.5\u001b[0m\n",
      "\u001b[34mEpoch 7/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.5388759071658175 accuracy 0.7888386123680241\u001b[0m\n",
      "\u001b[34mVal loss 0.21995411813259125 accuracy 1.0\u001b[0m\n",
      "\u001b[34m/opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34mEpoch 8/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.49176953351461744 accuracy 0.7888386123680241\u001b[0m\n",
      "\u001b[34mVal loss 0.3952715992927551 accuracy 0.75\u001b[0m\n",
      "\u001b[34mEpoch 9/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.40764510622584677 accuracy 0.8423831070889894\u001b[0m\n",
      "\u001b[34mVal loss 0.3331224322319031 accuracy 0.875\u001b[0m\n",
      "\u001b[34mEpoch 10/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\n",
      "2022-05-23 17:40:17 Uploading - Uploading generated training model\u001b[34mTrain loss 0.3815918499716075 accuracy 0.8529411764705882\u001b[0m\n",
      "\u001b[34mVal loss 0.424811452627182 accuracy 0.75\u001b[0m\n",
      "\u001b[34mBest val accuracy: 1.0\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/83.3M [00:00<?, ?B/s]#015 15%|█▌        | 12.8M/83.3M [00:00<00:00, 133MB/s]#015 31%|███       | 25.5M/83.3M [00:00<00:00, 132MB/s]#015 56%|█████▌    | 46.5M/83.3M [00:00<00:00, 172MB/s]#015 87%|████████▋ | 72.7M/83.3M [00:00<00:00, 212MB/s]#015100%|██████████| 83.3M/83.3M [00:00<00:00, 191MB/s]\u001b[0m\n",
      "\u001b[34m2022-05-23 17:40:13,362 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-05-23 17:40:37 Completed - Training job completed\n",
      "Training seconds: 614\n",
      "Billable seconds: 614\n",
      "CPU times: user 1.55 s, sys: 109 ms, total: 1.66 s\n",
      "Wall time: 12min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTE:** <br>\n",
    "If at this point your kernel disconnects from the server (you can tell because the kernel in the top right hand corner will say **No Kernel**),<br>you can reattach to the training job (so you dont to start the training job again).<br>Follow the steps below\n",
    "1. Scoll your notebook to the top and set the kernel to the recommended kernel specified in the top right hand corner of the notebook\n",
    "2. Go to your SageMaker console, Go to Training Jobs and copy the name of the training job you were disconnected from\n",
    "3. Scoll to the bottom of this notebook, paste your training job name to replace the **your-training-job-name** in the cell\n",
    "4. Replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook\n",
    "5. Run the edited cell\n",
    "6. Return to this cell and continue executing the rest of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the model_data method on the estimator to find the location of the trained model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-779416346969/pytorch-training-2022-05-23-17-28-34-228/output/model.tar.gz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploying a model\n",
    "Once trained, deploying a model is a simple call.\n",
    "\n",
    "**Note:** Replace the **'your_model_uri'** with the URI from the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "pytorch_model = PyTorchModel(model_data='s3://sagemaker-us-east-1-779416346969/pytorch-training-2022-05-23-17-28-34-228/output/model.tar.gz', \n",
    "                             role=role, \n",
    "                             entry_point='ptInfCode.py', \n",
    "                             framework_version='1.7',\n",
    "                             py_version='py3')\n",
    "predictor = pytorch_model.deploy(instance_type='ml.m5.4xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the endpoint name from predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-inference-2022-05-23-17-44-03-444\n"
     ]
    }
   ],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our endpoint is up and running, lets test it with an image and see how well it does\n",
    "In the cell below, replace the **your_endpoint_name** with the your endpoint name you had printed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 ms, sys: 0 ns, total: 15.4 ms\n",
      "Wall time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "im_name=\"../data/test/Signal/S2.png\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName='pytorch-inference-2022-05-23-17-44-03-444',\n",
    "    ContentType='application/x-image',\n",
    "    Body=open(im_name, 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us view the JSON response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.loads(response['Body'].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released.  Run the following cell to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to a training job that has been left to run \n",
    "\n",
    "If your kernel becomes disconnected and your training has already started, you can reattach to the training job.<br>\n",
    "In the cell below, replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook<br>\n",
    "Simply look up the training job name and replace the **your-training-job-name** and then run the cell below. <br>\n",
    "Once the training job is finished, you can continue the cells after the training cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "bucket = \"your-unique-bucket-name\"\n",
    "\n",
    "training_job_name = 'your-training-job-name'\n",
    "\n",
    "if 'your-training' not in training_job_name:\n",
    "    estimator = sagemaker.estimator.Estimator.attach(training_job_name=training_job_name, sagemaker_session=sess)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
