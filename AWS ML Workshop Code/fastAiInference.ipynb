{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> &uarr;   Ensure Kernel is set to  &uarr;  </div><br><div style=\"text-align: right\"> \n",
    "conda_amazonei_pytorch_latest_p36  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom FastAI Model Inference using PyTorch Base Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks you through setting up FastAI Model you just trained using BYOC for inference using endpoint. First we need to create a Predictor class to accept jpeg images as input and output JSON. The default behaviour is to accept a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Sagemaker SDK if not already done so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (2.86.2)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.91.1.tar.gz (534 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs==20.3.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: boto3>=1.20.21 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (1.21.42)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (1.21.6)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (3.20.0rc2)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (1.3.5)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.42 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker) (1.24.42)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from boto3>=1.20.21->sagemaker) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (3.0.8)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from pandas->sagemaker) (2022.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.42->boto3>=1.20.21->sagemaker) (1.26.8)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.91.1-py2.py3-none-any.whl size=737693 sha256=982244f2b1d5090c72082c1c4f4ae988c22e405b5a8bbf1a05c2734a2c1ee42c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/04/e3/8b/f78ee9433f86f32121824c2e287304bb364f4f600f766da233\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.86.2\n",
      "    Uninstalling sagemaker-2.86.2:\n",
      "      Successfully uninstalled sagemaker-2.86.2\n",
      "Successfully installed sagemaker-2.91.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please replace the **your-trained-model-uri** with the S3 URI location of your Fast AI Model from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_loc='s3://sagemaker-us-east-1-779416346969/script-mode-container-fastai-2022-05-23-18-25-48-446/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Image Predictor Class\n",
    "\n",
    "In the next cell, we will update the predictor class to accept json serializer and deserializer and accept application/x-image content type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Predictor\n",
    "jpeg_serializer = sagemaker.serializers.IdentitySerializer(\"application/x-image\")\n",
    "json_deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "\n",
    "class ImagePredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(ImagePredictor, self).__init__(\n",
    "            endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            serializer=jpeg_serializer,\n",
    "            deserializer=json_deserializer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ineference Script\n",
    "Create an Inference Script along with any libraries we need installed inside requirements.txt and save them in the inf_src folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import logging, requests, os, io, glob, time\n",
      "from fastai.vision.all import *\n",
      "from PIL import Image\n",
      "import json\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "\n",
      "JSON_CONTENT_TYPE = 'application/json'\n",
      "PNG_CONTENT_TYPE = 'application/x-image'\n",
      "\n",
      "# loads the model into memory from disk and returns it\n",
      "def model_fn(model_dir):\n",
      "    logger.info('model_fn')\n",
      "    learn = load_learner(os.path.join(model_dir, 'model.pth'))\n",
      "    return learn\n",
      "\n",
      "# Deserialize the Invoke request body into an object we can perform prediction on\n",
      "def input_fn(request_body, content_type=PNG_CONTENT_TYPE):\n",
      "    logger.info('Deserializing the input data.')\n",
      "    # process an image uploaded to the endpoint\n",
      "    # if content_type == PNG_CONTENT_TYPE: return open_image(io.BytesIO(request_body))\n",
      "    if content_type == PNG_CONTENT_TYPE:\n",
      "        \n",
      "        # image_data = Image.open(io.BytesIO(request_body))\n",
      "        image_data=bytes(request_body)\n",
      "        return(image_data)\n",
      "    # process a URL submitted to the endpoint\n",
      "    raise Exception('Requested unsupported ContentType in content_type: {}'.format(content_type))\n",
      "\n",
      "# Perform prediction on the deserialized object, with the loaded model\n",
      "def predict_fn(input_object, model):\n",
      "    logger.info(\"Calling model\")\n",
      "    start_time = time.time()\n",
      "    predict_class,predict_idx,predict_values = model.predict(input_object)\n",
      "    print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))\n",
      "    print(f'Predicted class is {str(predict_class)}')\n",
      "    print(f'Predict confidence score is {predict_values[predict_idx.item()].item()}')\n",
      "    return dict(class_name = str(predict_class),\n",
      "        confidence = predict_values[predict_idx.item()].item())\n",
      "\n",
      "# Serialize the prediction result into the desired response content type\n",
      "def output_fn(prediction, accept=JSON_CONTENT_TYPE):        \n",
      "    logger.info('Serializing the generated output.')\n",
      "    if accept == JSON_CONTENT_TYPE: return json.dumps(prediction), accept\n",
      "    raise Exception('Requested unsupported ContentType in Accept: {}'.format(accept))  "
     ]
    }
   ],
   "source": [
    "%cat inf_src/serve.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai==2.4"
     ]
    }
   ],
   "source": [
    "%cat inf_src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the model\n",
    "Using the model and ImagePredictor class from above, prepare the model for deployment as an endpoint and provide a serving script that can upack the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "model=PyTorchModel(model_data=s3_model_loc, \n",
    "                   name=name_from_base(\"fastai-custom-cont-mod\"),\n",
    "                   role=role, \n",
    "                   framework_version='1.8.0',\n",
    "                   py_version='py3',\n",
    "                   entry_point='inf_src/serve.py',\n",
    "                   source_dir= 'inf_src',\n",
    "                   predictor_cls=ImagePredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model \n",
    "\n",
    "Deploy the model to the end point using ml.m4.xlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!CPU times: user 5.94 s, sys: 1.25 s, total: 7.19 s\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your endpoint name is \n",
      "fastai-custom-cont-mod-2022-05-23-18-46-44-308\n"
     ]
    }
   ],
   "source": [
    "print(f'Your endpoint name is \\n{predictor.endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Predictor to make inference \n",
    "\n",
    "**NOTE** Replace **your-endpoint-name** with your endpoint name in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"class_name\": \"Roundabout\", \"confidence\": 0.9826133847236633}'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.predictor import json_serializer\n",
    "\n",
    "#copy the endpoint name and update from sagemaker console --> inference-endpoints\n",
    "endpoint_name='fastai-custom-cont-mod-2022-05-23-18-46-44-308'\n",
    "\n",
    "predictor=Predictor(endpoint_name=endpoint_name, \n",
    "                    sagemaker_session=sagemaker_session,serializer=jpeg_serializer)\n",
    "\n",
    "with open('../data/test/Roundabout/R1.png', 'rb') as f:\n",
    "    img_byte=f.read()\n",
    "    print(predictor.predict(img_byte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Boto3 Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "client=boto3.client('sagemaker-runtime')\n",
    "im_name=\"../data/test/Roundabout/R2.png\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "EndpointName=endpoint_name,\n",
    "ContentType='application/x-image',\n",
    "Body=open(im_name, 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'Roundabout', 'confidence': 0.8730788826942444}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(response['Body'].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released.  Run the following cell to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
